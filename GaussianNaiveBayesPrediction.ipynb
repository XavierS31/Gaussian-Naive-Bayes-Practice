{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "893b1a6f-8c4f-4c16-b668-f944b898be32",
   "metadata": {},
   "source": [
    "# Gaussian Naive Bayes (from scratch)\n",
    "\n",
    "### Name :\n",
    "Xavier Soto\n",
    "\n",
    "\n",
    "Goal: implement Gaussian Naive Bayes to classify handwritten digits, evaluate its performance, and analyze results.\n",
    "\n",
    "---\n",
    "\n",
    "## Assumptions of Gaussian Naive Bayes\n",
    "\n",
    "- Features are treated as **independent** given the class label.  \n",
    "- Each feature (per class) is modeled by a Gaussian distribution:\n",
    "  \n",
    "$$\n",
    "x_i \\mid C_k \\sim \\mathcal{N}(\\mu_{ik}, \\sigma^2_{ik})\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## Decision Rule (MAP)\n",
    "\n",
    "We predict the most probable class:\n",
    "\n",
    "$$\n",
    "\\hat{c} = \\arg\\max_c \\left[\\log P(C=c) + \\sum_i \\log P(x_i \\mid C=c)\\right]\n",
    "$$\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f78a5d-c9f4-4067-842b-845ce7eea939",
   "metadata": {},
   "source": [
    "## Dataset Loading\n",
    "\n",
    "We use MNIST (70,000 images of 28×28 digits). If unavailable, fallback to sklearn's smaller digit dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "706da8d8-931b-4d51-ae1c-b6ec15225edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (70000, 784) (70000,)\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml, load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Load MNIST (normalize to [0,1]); fallback to sklearn digits\n",
    "try:\n",
    "    mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
    "    X, y = mnist.data / 255.0, mnist.target.astype(int)\n",
    "except Exception:\n",
    "    digits = load_digits()\n",
    "    X, y = digits.data / 16.0, digits.target\n",
    "\n",
    "#Print\n",
    "print(\"Data shape:\", X.shape, y.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc64271-db57-4bb0-9a84-3cc5326553c0",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "Let’s preview a few images with their labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b249632e-7429-4f21-b36d-0505505c3cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x200 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 5, figsize=(10, 2))\n",
    "for i, ax in enumerate(axes):\n",
    "    size = int(np.sqrt(X.shape[1]))\n",
    "    ax.imshow(X[i].reshape(size, size), cmap=\"gray\")\n",
    "    ax.set_title(f\"Label: {y[i]}\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "#Visualize the images\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1954d25-4604-4e55-814b-7ce5e934bb2a",
   "metadata": {},
   "source": [
    "## Training Step\n",
    "\n",
    "We must estimate:\n",
    "- Class prior $$P(C_k) = N_k/N $$\n",
    "- Mean $$\\mu_{ik} \\;=\\; \\frac{1}{N_k} \\sum_{j:\\, y_j = C_k} x_{ij}$$\n",
    "  Where ($x_{ij}$): value of feature $(i$) for sample $(j$) in class $(C_k$)\n",
    "  \n",
    "- variance $$\n",
    "\\sigma^2_{ik} \\;=\\; \\frac{1}{N_k} \\sum_{j:\\, y_j = C_k} \\big(x_{ij} - \\mu_{ik}\\big)^2\n",
    "$$  for each feature given class.\n",
    "\n",
    "These define the Gaussian likelihoods as the following:\n",
    "\n",
    "\n",
    "**Gaussian Likelihood (per feature given a class):**\n",
    "$$\n",
    "P(x_i \\mid C_k) \\;=\\; \\frac{1}{\\sqrt{2 \\pi \\sigma^2_{ik}}} \n",
    "\\exp\\!\\left(-\\frac{(x_i - \\mu_{ik})^2}{2\\sigma^2_{ik}}\\right)\n",
    "$$  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5a94be9-6dac-4ce4-b9bd-033369d80ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset splitted\n",
      "Train: (56000, 784)\n",
      "Test: (14000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Split dataset\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "#Print the split dataset\n",
    "print(\"Dataset splitted\")\n",
    "print(\"Train:\", X_train.shape)\n",
    "print(\"Test:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78a0bb1-1230-4044-bde8-7d55bbedd742",
   "metadata": {},
   "source": [
    "# Implementation: Gaussian Naive Bayes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba5aac0-28fa-4121-9966-ff1eaa193462",
   "metadata": {},
   "source": [
    "## Prediction with Gaussian Naive Bayes\n",
    "\n",
    "---\n",
    "\n",
    "### Prediction Rule\n",
    "\n",
    "For a given sample $x = (x_1, x_2, \\dots, x_d)$, we compute the **log posterior** for each class $C_k$:\n",
    "\n",
    "$$\n",
    "\\text{score}(C_k \\mid x) \n",
    "= \\log P(C_k) \n",
    "- \\frac{1}{2}\\sum_{i=1}^d \\Bigg[ \\log\\big(2\\pi \\sigma^2_{ik}\\big) \n",
    "+ \\frac{(x_i - \\mu_{ik})^2}{\\sigma^2_{ik}} \\Bigg]\n",
    "$$\n",
    "\n",
    "The predicted class is the one with the maximum score:\n",
    "\n",
    "$$\n",
    "\\hat{c} = \\arg\\max_k \\; \\text{score}(C_k \\mid x)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "**Notes:**\n",
    "- The summation runs over all features $i$.  \n",
    "- We use logarithms to stabilize the computation.  \n",
    "- $\\hat{c}$ is the final class label returned by the classifier.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01e61067-2747-4672-9027-8c3595dab0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gaussian Naives Bayes\n",
    "class GaussianNBStudent:\n",
    "    def __init__(self, var_smoothing=1e-9):\n",
    "        self.var_smoothing = var_smoothing\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        #Estimate priors, means, and variances per class.\n",
    "        self.classes = np.unique(y)\n",
    "        self.priors = {}\n",
    "        self.means = {}\n",
    "        self.vars = {}\n",
    "        for c in self.classes:\n",
    "            X_c = X[y == c]\n",
    "            self.priors[c] = X_c.shape[0] / X.shape[0]\n",
    "            self.means[c] = X_c.mean(axis=0)\n",
    "            self.vars[c] = X_c.var(axis=0) + self.var_smoothing\n",
    "\n",
    "    def _log_posterior(self, x):\n",
    "        #Return unnormalized log posterior for each class.\n",
    "        scores = {}\n",
    "        for c in self.classes:\n",
    "            μ = self.means[c]\n",
    "            σ2 = self.vars[c]\n",
    "            prior = np.log(self.priors[c])\n",
    "            likelihood = -0.5 * np.sum(np.log(2*np.pi*σ2))\n",
    "            likelihood -= 0.5 * np.sum(((x - μ)**2) / σ2)\n",
    "            scores[c] = prior + likelihood\n",
    "        return scores\n",
    "\n",
    "    #Prediction\n",
    "    def predict(self, X):\n",
    "        preds = []\n",
    "        for x in X:\n",
    "            scores = [self._log_posterior(x)[c] for c in self.classes]\n",
    "            c_hat = self.classes[np.argmax(scores)]  # argmax over classes\n",
    "            preds.append(c_hat)\n",
    "        return np.array(preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67deeb53-66ef-4ff2-bf41-393f4820a154",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "We evaluate using:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1-score\n",
    "- Confusion matrix\n",
    "\n",
    "---\n",
    "\n",
    "### Formulas:\n",
    "\n",
    "- **Accuracy**\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{TP+TN}{TP+TN+FP+FN}\n",
    "$$\n",
    "\n",
    "\n",
    "- **Precision**\n",
    "$$\n",
    "\\text{Precision} = \\frac{TP}{TP+FP}, \n",
    "$$\n",
    "\n",
    "- **Recall**\n",
    "\n",
    "$$\n",
    "\\quad \\text{Recall} = \\frac{TP}{TP+FN}\n",
    "$$\n",
    "\n",
    "- **F1 Score**\n",
    "$$\n",
    "F1 = \\frac{2 \\cdot P \\cdot R}{P+R}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1405f45b-ebb6-41f2-b16b-ece426ed8779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5649285714285714\n",
      "[[1179    4    4    3    4    6   46    0  110   25]\n",
      " [   0 1487    5    3    0    5   22    2   34   17]\n",
      " [  97   31  462  101   10    7  337    3  333   17]\n",
      " [  39   76   11  514    3    9   60    8  579  129]\n",
      " [  21   15   19   12  230    6   92    8  315  647]\n",
      " [  94   46   10   26    5   67   59    4  831  121]\n",
      " [  13   35    9    1    1    3 1272    0   38    3]\n",
      " [   4   14    1   11   10    2    5  477   50  885]\n",
      " [  20  188    8    6    4    8   13    2  923  193]\n",
      " [   6   16    2    3    9    0    2   25   30 1298]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.85      0.83      1381\n",
      "           1       0.78      0.94      0.85      1575\n",
      "           2       0.87      0.33      0.48      1398\n",
      "           3       0.76      0.36      0.49      1428\n",
      "           4       0.83      0.17      0.28      1365\n",
      "           5       0.59      0.05      0.10      1263\n",
      "           6       0.67      0.93      0.77      1375\n",
      "           7       0.90      0.33      0.48      1459\n",
      "           8       0.28      0.68      0.40      1365\n",
      "           9       0.39      0.93      0.55      1391\n",
      "\n",
      "    accuracy                           0.56     14000\n",
      "   macro avg       0.69      0.56      0.52     14000\n",
      "weighted avg       0.69      0.56      0.53     14000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and predict\n",
    "model = GaussianNBStudent()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bae6bc-e196-4455-bef9-052ef0384177",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "**Overall Accuracy:**  \n",
    "- Accuracy: **0.565 (~56%)**\n",
    "\n",
    "---\n",
    "\n",
    "**Class Performance (from confusion matrix):**  \n",
    "- Strong recall: digits **0, 1, 6, 9** (well recognized by the model).  \n",
    "- Weak recall: digits **2, 3, 4, 5, 7** (frequently misclassified).  \n",
    "- Mixed case: digit **8** shows high recall but low precision, meaning it is predicted too often.\n",
    "\n",
    "---\n",
    "\n",
    "**Evaluation Metrics:**  \n",
    "- Macro average precision: 0.69  \n",
    "- Macro average recall: 0.56  \n",
    "- Macro average F1-score: 0.52  \n",
    "- Confirms that the classifier handles some classes well while struggling with others.\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "The Gaussian Naive Bayes classifier was implemented and tested on handwritten digits.  \n",
    "- It correctly identifies some digits with high confidence, while others overlap heavily and are confused.  \n",
    "- The confusion matrix shows clear patterns of misclassification across several classes.  \n",
    "- Overall, Naive Bayes demonstrates its usefulness as a **baseline model**: simple, efficient, and above random guessing, but too limited to capture the complex distributions in digit data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266791f7-d92e-4670-b66d-22f3c7d92424",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
